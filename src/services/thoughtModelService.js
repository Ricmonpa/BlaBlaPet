import { GoogleGenerativeAI } from '@google/generative-ai';

/**
 * Servicio de An√°lisis con Modelo de Pensamiento
 * Implementa el prompt de an√°lisis paso a paso para comportamiento canino
 */
class ThoughtModelService {
  constructor() {
    this.apiKey = import.meta.env.VITE_GEMINI_API_KEY;
    if (!this.apiKey) {
      console.warn('‚ö†Ô∏è VITE_GEMINI_API_KEY no encontrada');
      return;
    }
    
    this.genAI = new GoogleGenerativeAI(this.apiKey);
    this.model = this.genAI.getGenerativeModel({ model: "gemini-1.5-flash" });
  }

  /**
   * Analiza media de mascota usando el modelo de pensamiento
   * @param {string} mediaData - Base64 o blob de la imagen/video
   * @param {string} mediaType - 'image' o 'video'
   * @returns {Object} Resultado del an√°lisis
   */
  async analyzePetMediaWithThoughtModel(mediaData, mediaType = 'image') {
    try {
      console.log('üß† Iniciando an√°lisis con modelo de pensamiento...');
      
      if (!this.apiKey) {
        throw new Error('API Key de Gemini no configurada');
      }

      // Preparar el prompt exacto proporcionado
      const prompt = `Eres un analista de lenguaje corporal canino de nivel experto. Tu tarea es analizar un video de un perro y generar una descripci√≥n detallada de su comportamiento.

Para lograrlo, sigue este proceso de pensamiento:

1. **Observaci√≥n y Registro:** Examina el video cuadro por cuadro para identificar cada movimiento, postura, y vocalizaci√≥n (si la hubiera) del perro. Anota las se√±ales clave:
   * Postura del cuerpo (relajada, tensa, inclinada, etc.).
   * Posici√≥n de la cola (alta, baja, movi√©ndose, r√≠gida).
   * Posici√≥n de las orejas (hacia adelante, hacia atr√°s, relajadas).
   * Acciones espec√≠ficas (sacudir un objeto, reverencia de juego, etc.).
   * Interacciones con el entorno (mirar a la c√°mara, a una persona, a otro objeto).

2. **An√°lisis e Interpretaci√≥n:** Bas√°ndote en tu registro, interpreta el significado de cada se√±al en el contexto del comportamiento canino. No te limites a describir lo que ves, explica el porqu√©. Por ejemplo, una "reverencia de juego" no es solo una postura, es una invitaci√≥n a la interacci√≥n.

3. **Traducci√≥n a Lenguaje Humano:** Una vez que comprendas la intenci√≥n del perro, traduce esa energ√≠a y esas se√±ales a palabras humanas. No se trata de una traducci√≥n literal, sino de una interpretaci√≥n que captura la emoci√≥n y el mensaje del perro. Usa un lenguaje que sea natural y comprensible para el due√±o.

4. **Generaci√≥n de la Respuesta Final:** Combina la descripci√≥n detallada, el an√°lisis y la traducci√≥n en una respuesta coherente y fluida, como si fueras un experto en comunicaci√≥n canina. Tu tono debe ser **tranquilo, asertivo y claro**.

Responde en formato JSON con la siguiente estructura:
{
  "observacion_detallada": "Descripci√≥n paso a paso de lo observado",
  "analisis_interpretacion": "Explicaci√≥n del significado de cada se√±al",
  "traduccion_humana": "Lo que el perro est√° 'diciendo' en palabras humanas",
  "respuesta_final": "S√≠ntesis completa del an√°lisis",
  "confianza": 85,
  "emocion_detectada": "estado emocional principal",
  "comportamiento_principal": "descripci√≥n del comportamiento clave"
}`;

      // Usar la misma l√≥gica que funciona en geminiService
      const mediaPart = await this.prepareMediaForGemini(mediaData, mediaType);
      
      // Preparar el contenido multimedia
      const content = [
        { text: prompt },
        mediaPart
      ];

      console.log('üì§ Enviando solicitud a Gemini...');
      
      // Configurar timeout adaptativo para videos largos
      const controller = new AbortController();
      const timeoutId = setTimeout(() => controller.abort(), 180000); // 180 segundos para videos largos

      const result = await this.model.generateContent({
        contents: [{ role: "user", parts: content }],
        generationConfig: {
          temperature: 0.2,
          topK: 20,
          topP: 0.8,
          maxOutputTokens: 1024,
        }
      });

      clearTimeout(timeoutId);

      const response = await result.response;
      const text = response.text();
      
      console.log('üì• Respuesta recibida de Gemini');
      console.log('üìù Respuesta completa:', text);

      // Intentar parsear como JSON
      let parsedResult;
      try {
        // Limpiar la respuesta para extraer solo el JSON
        const jsonMatch = text.match(/\{[\s\S]*\}/);
        if (jsonMatch) {
          parsedResult = JSON.parse(jsonMatch[0]);
        } else {
          throw new Error('No se encontr√≥ JSON v√°lido en la respuesta');
        }
      } catch (parseError) {
        console.warn('‚ö†Ô∏è Error parseando JSON, usando respuesta como texto:', parseError);
        parsedResult = {
          observacion_detallada: text,
          analisis_interpretacion: "An√°lisis no estructurado",
          traduccion_humana: "Traducci√≥n no disponible",
          respuesta_final: text,
          confianza: 50,
          emocion_detectada: "indeterminada",
          comportamiento_principal: "an√°lisis directo"
        };
      }

      // Formatear resultado para compatibilidad
      const formattedResult = {
        translation: parsedResult.traduccion_humana || parsedResult.respuesta_final,
        confidence: parsedResult.confianza || 75,
        emotion: parsedResult.emocion_detectada || "neutral",
        behavior: parsedResult.comportamiento_principal || "comportamiento observado",
        context: parsedResult.analisis_interpretacion || "contexto no disponible",
        thoughtProcess: {
          observacion: parsedResult.observacion_detallada,
          analisis: parsedResult.analisis_interpretacion,
          traduccion: parsedResult.traduccion_humana,
          respuestaFinal: parsedResult.respuesta_final
        },
        source: 'thought_model',
        success: true
      };

      console.log('‚úÖ An√°lisis con modelo de pensamiento completado');
      return formattedResult;

    } catch (error) {
      console.error('‚ùå Error en an√°lisis con modelo de pensamiento:', error);
      
      // Fallback en caso de error
      return {
        translation: "No pude analizar el comportamiento del perro en este momento.",
        confidence: 0,
        emotion: "indeterminada",
        behavior: "an√°lisis no disponible",
        context: "Error en el procesamiento",
        thoughtProcess: {
          observacion: "Error en la observaci√≥n",
          analisis: "Error en el an√°lisis",
          traduccion: "Error en la traducci√≥n",
          respuestaFinal: "Error en la respuesta final"
        },
        source: 'thought_model_error',
        success: false,
        error: error.message
      };
    }
  }

  /**
   * Preparar media para Gemini (copiado del geminiService que funciona)
   * @param {string|Blob} mediaData - Datos de media
   * @param {string} mediaType - Tipo de media
   * @returns {Promise<Object>} Media part para Gemini
   */
  async prepareMediaForGemini(mediaData, mediaType) {
    try {
      if (mediaType === 'image') {
        // Para im√°genes (base64 o blob)
        if (typeof mediaData === 'string' && mediaData.startsWith('data:')) {
          // Es base64, convertir a blob
          const response = await fetch(mediaData);
          const blob = await response.blob();
          return {
            inlineData: {
              data: await this.blobToBase64(blob),
              mimeType: blob.type
            }
          };
        } else if (mediaData instanceof Blob) {
          // Es blob, convertir a base64
          return {
            inlineData: {
              data: await this.blobToBase64(mediaData),
              mimeType: mediaData.type
            }
          };
        } else if (mediaData.startsWith('blob:')) {
          // Es blob URL, convertir a blob y luego a base64
          const response = await fetch(mediaData);
          const blob = await response.blob();
          return {
            inlineData: {
              data: await this.blobToBase64(blob),
              mimeType: blob.type
            }
          };
        }
      } else if (mediaType === 'video') {
        // Para videos, extraer frame clave o usar thumbnail
        const videoBlob = mediaData instanceof Blob ? mediaData : await fetch(mediaData).then(r => r.blob());
        
        // Detectar duraci√≥n del video para decidir estrategia
        const videoDuration = await this.getVideoDuration(videoBlob);
        console.log(`üé¨ Video duration detected: ${videoDuration}s`);
        
        if (videoDuration > 15) {
          // Video largo: usar m√∫ltiples frames para an√°lisis completo
          console.log('üé¨ Video largo detectado - usando an√°lisis multi-frame');
          const frames = await this.createMultipleVideoFrames(videoBlob);
          
          // Retornar el primer frame como principal (compatibilidad)
          return {
            inlineData: {
              data: frames[0].base64,
              mimeType: 'image/jpeg'
            },
            // A√±adir frames adicionales para an√°lisis extendido
            additionalFrames: frames.slice(1)
          };
        } else {
          // Video corto: usar thumbnail tradicional (mantener l√≥gica actual)
          console.log('üé¨ Video corto - usando thumbnail tradicional');
          const thumbnail = await this.createVideoThumbnail(videoBlob);
          
          return {
            inlineData: {
              data: thumbnail,
              mimeType: 'image/jpeg'
            }
          };
        }
      }
      
      // Fallback
      throw new Error('Formato de media no soportado');
    } catch (error) {
      console.error('Error preparando media para Gemini:', error);
      throw error;
    }
  }

  /**
   * Convertir blob a Base64 (copiado del geminiService que funciona)
   * @param {Blob} blob - Blob a convertir
   * @returns {Promise<string>} Base64 string
   */
  blobToBase64(blob) {
    return new Promise((resolve, reject) => {
      const reader = new FileReader();
      reader.onload = () => {
        const base64 = reader.result.split(',')[1];
        resolve(base64);
      };
      reader.onerror = reject;
      reader.readAsDataURL(blob);
    });
  }

  /**
   * Crear thumbnail de video (copiado del geminiService que funciona)
   * @param {Blob} videoBlob - Blob del video
   * @returns {Promise<string>} Base64 del thumbnail
   */
  createVideoThumbnail(videoBlob) {
    return new Promise((resolve, reject) => {
      const video = document.createElement('video');
      const canvas = document.createElement('canvas');
      const ctx = canvas.getContext('2d');
      
      video.onloadedmetadata = () => {
        // Tomar frame en el 25% del video
        video.currentTime = video.duration * 0.25;
      };
      
      video.onseeked = () => {
        canvas.width = video.videoWidth;
        canvas.height = video.videoHeight;
        ctx.drawImage(video, 0, 0);
        
        canvas.toBlob((blob) => {
          this.blobToBase64(blob).then(resolve).catch(reject);
        }, 'image/jpeg', 0.8);
      };
      
      video.onerror = reject;
      video.src = URL.createObjectURL(videoBlob);
    });
  }

  /**
   * Obtener duraci√≥n del video (NUEVA FUNCIONALIDAD)
   * @param {Blob} videoBlob - Blob del video
   * @returns {Promise<number>} Duraci√≥n en segundos
   */
  getVideoDuration(videoBlob) {
    return new Promise((resolve, reject) => {
      const video = document.createElement('video');
      
      video.onloadedmetadata = () => {
        resolve(video.duration);
      };
      
      video.onerror = reject;
      video.src = URL.createObjectURL(videoBlob);
    });
  }

  /**
   * Crear m√∫ltiples frames de video para an√°lisis completo (NUEVA FUNCIONALIDAD)
   * @param {Blob} videoBlob - Blob del video
   * @returns {Promise<Array>} Array de frames en base64
   */
  createMultipleVideoFrames(videoBlob) {
    return new Promise((resolve, reject) => {
      const video = document.createElement('video');
      const canvas = document.createElement('canvas');
      const ctx = canvas.getContext('2d');
      const frames = [];
      const framePositions = [0, 0.25, 0.5, 0.75, 1.0]; // 0%, 25%, 50%, 75%, 100%
      let currentFrameIndex = 0;
      
      video.onloadedmetadata = () => {
        console.log(`üé¨ Video duration: ${video.duration}s - Generando ${framePositions.length} frames`);
        canvas.width = video.videoWidth;
        canvas.height = video.videoHeight;
        
        // Procesar primer frame
        video.currentTime = video.duration * framePositions[currentFrameIndex];
      };
      
      video.onseeked = () => {
        ctx.drawImage(video, 0, 0);
        
        canvas.toBlob((blob) => {
          this.blobToBase64(blob).then(base64 => {
            frames.push({
              position: framePositions[currentFrameIndex],
              time: video.duration * framePositions[currentFrameIndex],
              base64: base64
            });
            
            currentFrameIndex++;
            
            // Procesar siguiente frame
            if (currentFrameIndex < framePositions.length) {
              video.currentTime = video.duration * framePositions[currentFrameIndex];
            } else {
              // Todos los frames procesados
              console.log(`‚úÖ Generados ${frames.length} frames para an√°lisis completo`);
              resolve(frames);
            }
          }).catch(reject);
        }, 'image/jpeg', 0.8);
      };
      
      video.onerror = reject;
      video.src = URL.createObjectURL(videoBlob);
    });
  }

  /**
   * Verificar si el servicio est√° disponible
   * @returns {boolean}
   */
  isAvailable() {
    return !!this.apiKey && !!this.genAI;
  }
}

export default new ThoughtModelService();
